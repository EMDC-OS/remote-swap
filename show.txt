commit c993a6f7bb04910d6800d7d53cc4bdd1e92b24b0
Author: JinyongPark <jinyong.park@csi.skku.edu>
Date:   Tue Jul 12 12:39:37 2022 +0900

    OR and AFTER 2

diff --git a/msm-google/jyp/remote.c b/msm-google/jyp/remote.c
index 1c628cefd..2d25ecff7 100644
--- a/msm-google/jyp/remote.c
+++ b/msm-google/jyp/remote.c
@@ -165,7 +165,7 @@ void wake_up_send_target_manager(void)
 
 
 
-static int _send_target_page(unsigned int id, pte_t *pte, pmd_t *pmd, unsigned long vpage, struct mm_struct *mm, bool is_after){
+static int _send_target_page(unsigned int id, pte_t *pte, pmd_t *pmd, unsigned long vpage, struct mm_struct *mm){
 
 
 
@@ -194,7 +194,7 @@ static int _send_target_page(unsigned int id, pte_t *pte, pmd_t *pmd, unsigned l
 					
 	//trace_printk(KERN_ERR "[REMOTE %s] alloc page %llx\n", __func__,page_to_pfn(page));
 
-		new_entry = get_swap_page_of_id(id+10*is_after);
+		new_entry = get_swap_page_of_id(id);
 	new_pte = swp_entry_and_counter_to_pte(new_entry,id);
 	//if Prefetch target, type==1 && counter(id)==id
 	lock_page(page);
@@ -238,7 +238,7 @@ static int _send_target_page(unsigned int id, pte_t *pte, pmd_t *pmd, unsigned l
 	}
 	
 	set_pte(orig_pte, new_pte);
-	trace_printk("target sent id %d: cluster %d, %d %llx %llx\n",id,id+10*is_after,mm->owner->tgid, vpage, swp_offset(new_entry));
+	trace_printk("target sent id %d: %d %llx %llx\n",id, mm->owner->tgid, vpage, swp_offset(new_entry));
 	swap_free(entry);
 	ret=1;
 unlock:
@@ -838,14 +838,11 @@ static void prefetch_work(struct work_struct *work)
 	struct prefetch_work *tew;
 	int max_idx_l;
 	int max_idx_e;
-	int after_idx_e;
-	int after_idx_l;
 	struct swap_trace_entry *swap_trace_table_l;
 	struct swap_trace_entry *swap_trace_table_e;
 	pid_t tgid;
 	unsigned long va;
 	struct blk_plug plug;
-	struct blk_plug plug_after;
 	int i;
 	unsigned int id;
 	int target_table;
@@ -854,62 +851,41 @@ static void prefetch_work(struct work_struct *work)
 	id = tew->id;
 	
 
-	//printk(KERN_ERR "1!!\n");
 	if(target_table){
 		max_idx_e = atomic_read(&past[id]->st_index0);
 		swap_trace_table_e = past[id]->swap_trace_table0;
 		max_idx_l = atomic_read(&past[id]->st_index1);
 		swap_trace_table_l = past[id]->swap_trace_table1;
-		after_idx_e = atomic_read(&past[id]->after_index0);
-		after_idx_l = atomic_read(&past[id]->after_index1);
 	}
 	else{
 		max_idx_e = atomic_read(&past[id]->st_index1);
 		swap_trace_table_e = past[id]->swap_trace_table1;
 		max_idx_l = atomic_read(&past[id]->st_index0);
 		swap_trace_table_l = past[id]->swap_trace_table0;
-		after_idx_e = atomic_read(&past[id]->after_index1);
-		after_idx_l = atomic_read(&past[id]->after_index0);
 	}
-	//printk(KERN_ERR "2 %d %d, %d %d!!\n",max_idx_e, after_idx_e, max_idx_l, after_idx_l);
 
-	blk_start_plug(&plug);
-	for( i = 0 ; i <= max_idx_l ; i++ ){
-	//printk(KERN_ERR "3!!\n");
-		//trace_printk("prefetch table %d: %d %llx, %d %d\n",target_table,swap_trace_table_l[i].tgid,swap_trace_table_l[i].va,swap_trace_table_l[i].to_nbd,swap_trace_table_l[i].swapped);
-		if(swap_trace_table_l[i].to_nbd && swap_trace_table_l[i].swapped){
-			tgid = swap_trace_table_l[i].tgid;
-			va = swap_trace_table_l[i].va;
-			prefetch_target_page(tgid,va);
-		}
-	}
-	blk_finish_plug(&plug);
 
-	//printk(KERN_ERR "4!!\n");
-
-	blk_start_plug(&plug_after);
-	for( i = max_idx_l + 1; i <= after_idx_l; i++ ){
-	//printk(KERN_ERR "5!!\n");
+	blk_start_plug(&plug);
+	for( i = 0 ; i < max_idx_l ; i++ ){
 		//trace_printk("prefetch table %d: %d %llx, %d %d\n",target_table,swap_trace_table_l[i].tgid,swap_trace_table_l[i].va,swap_trace_table_l[i].to_nbd,swap_trace_table_l[i].swapped);
 		if(swap_trace_table_l[i].to_nbd && swap_trace_table_l[i].swapped){
 			tgid = swap_trace_table_l[i].tgid;
 			va = swap_trace_table_l[i].va;
 			prefetch_target_page(tgid,va);
+			swap_trace_table_l[i].swapped = 0;
 		}
 	}
 
 
-	//printk(KERN_ERR "6!!\n");
-	for( i = max_idx_e + 1 ; i <= after_idx_e ; i++ ){
-	//printk(KERN_ERR "7!!\n");
+	for( i = 0 ; i < max_idx_e ; i++ ){
 		if(swap_trace_table_e[i].to_nbd && swap_trace_table_e[i].swapped){
 			tgid = swap_trace_table_e[i].tgid;
 			va = swap_trace_table_e[i].va;
 			prefetch_target_page(tgid,va);
+			swap_trace_table_e[i].swapped = 0;
 		}
 	}
-	//printk(KERN_ERR "8!!\n");
-	blk_finish_plug(&plug_after);
+	blk_finish_plug(&plug);
 	lru_add_drain();
 
 	kfree(tew);
@@ -921,8 +897,6 @@ static void miss_page_work(struct work_struct *work)
 	struct miss_page_work *tew;
 	int max_idx_l;
 	int max_idx_e;
-	int after_idx_l;
-	int after_idx_e;
 	struct swap_trace_entry *swap_trace_table_l;
 	struct swap_trace_entry *swap_trace_table_e;
 	pid_t tgid;
@@ -939,21 +913,17 @@ static void miss_page_work(struct work_struct *work)
 		swap_trace_table_e = past[id]->swap_trace_table0;
 		max_idx_l = atomic_read(&past[id]->st_index1);
 		swap_trace_table_l = past[id]->swap_trace_table1;
-		after_idx_e = atomic_read(&past[id]->after_index0);
-		after_idx_l = atomic_read(&past[id]->after_index1);
 	}
 	else{
 		max_idx_e = atomic_read(&past[id]->st_index1);
 		swap_trace_table_e = past[id]->swap_trace_table1;
 		max_idx_l = atomic_read(&past[id]->st_index0);
 		swap_trace_table_l = past[id]->swap_trace_table0;
-		after_idx_e = atomic_read(&past[id]->after_index1);
-		after_idx_l = atomic_read(&past[id]->after_index0);
 	}
 
 //	blk_start_plug(&plug);
-	for( i = 0 ; i <= after_idx_l ; i++ ){
-		if(swap_trace_table_l[i].to_nbd && swap_trace_table_l[i].swapped ) // && swapped
+	for( i = 0 ; i < max_idx_l ; i++ ){
+		if(swap_trace_table_l[i].to_nbd) // && swapped
 		{
 			tgid = swap_trace_table_l[i].tgid;
 			va = swap_trace_table_l[i].va;
@@ -961,8 +931,9 @@ static void miss_page_work(struct work_struct *work)
 		}
 	}
 
-	for( i = 0 ; i <= after_idx_e ; i++ ){
-		if(swap_trace_table_e[i].to_nbd && swap_trace_table_e[i].swapped) // && swapped
+
+	for( i = 0 ; i < max_idx_e ; i++ ){
+		if(swap_trace_table_e[i].to_nbd) // && swapped
 		{
 			tgid = swap_trace_table_e[i].tgid;
 			va = swap_trace_table_e[i].va;
@@ -1448,8 +1419,6 @@ int update_to_nbd_flag(unsigned int id, int percentage){
 	int idx_l; //latter
 	int max_idx_e;
 	int max_idx_l;
-	int after_idx_e;
-	int after_idx_l;
 	int cnt=0;
 	struct swap_trace_entry *swap_trace_table_e;
 	struct swap_trace_entry *swap_trace_table_l;
@@ -1464,19 +1433,14 @@ int update_to_nbd_flag(unsigned int id, int percentage){
 		swap_trace_table_e = past[id]->swap_trace_table0;
 		max_idx_l = atomic_read(&past[id]->st_index1);
 		swap_trace_table_l = past[id]->swap_trace_table1;
-		after_idx_e = atomic_read(&past[id]->after_index0);
-		after_idx_l = atomic_read(&past[id]->after_index1);
 	}
 	else{
 		max_idx_e = atomic_read(&past[id]->st_index1);
 		swap_trace_table_e = past[id]->swap_trace_table1;
 		max_idx_l = atomic_read(&past[id]->st_index0);
 		swap_trace_table_l = past[id]->swap_trace_table0;
-		after_idx_e = atomic_read(&past[id]->after_index1);	
-		after_idx_l = atomic_read(&past[id]->after_index0);
 	}
 
-
 	idx_e = max_idx_e * percentage/100;
 	idx_l = max_idx_l * percentage/100;
 
@@ -1484,7 +1448,7 @@ int update_to_nbd_flag(unsigned int id, int percentage){
 
 	/* AND version!*/
 	
-
+/*
 	while(idx_l <= max_idx_l){
 		idx_e = max_idx_e * percentage/100;
 		while(idx_e <= max_idx_e){
@@ -1498,25 +1462,23 @@ int update_to_nbd_flag(unsigned int id, int percentage){
 		}
 		idx_l++;
 	}
+*/
 
-	idx_e = max_idx_e + 1;
-	idx_l = max_idx_l + 1;
-	
-
-	while(idx_e <= after_idx_e){
+	/* OR version! */
+	while(idx_e <= max_idx_e){
 		swap_trace_table_e[idx_e].to_nbd = 1;
 		idx_e++;
 		cnt++;
 	}
-	while(idx_l <= after_idx_l){
+	while(idx_l <= max_idx_l){
 		swap_trace_table_l[idx_l].to_nbd = 1;
 		idx_l++;
 		cnt++;
 	}
-	idx_e = max_idx_e + 1;
-	while(idx_e <= after_idx_e){
-		idx_l = max_idx_l + 1;
-		while(idx_l <= after_idx_l){
+	idx_e = max_idx_e * percentage/100;
+	while(idx_e <= max_idx_e){
+		idx_l = max_idx_l * percentage/100;
+		while(idx_l <= max_idx_l){
 			if( swap_trace_table_e[idx_e].va == swap_trace_table_l[idx_l].va &&
 				swap_trace_table_e[idx_e].tgid == swap_trace_table_l[idx_l].tgid){
 				swap_trace_table_e[idx_e].to_nbd = 0;
@@ -1531,8 +1493,11 @@ int update_to_nbd_flag(unsigned int id, int percentage){
 
 	
 	// for dump
+	
 
-	trace_printk("appid %d: table %d is latter, total target %d max idx e, l -> %d %d, after %d %d\n",id, past[id]->which_table,cnt,max_idx_e,max_idx_l,after_idx_e - max_idx_e, after_idx_l - max_idx_l);
+	idx_l = max_idx_l * percentage/100;
+
+	trace_printk("appid %d: table %d is latter, total target %d max idx e, l -> %d %d\n",id, past[id]->which_table,cnt,max_idx_e,max_idx_l);
 /*
 	while(idx_l <= max_idx_l){
 		if( swap_trace_table_l[idx_l].to_nbd )
@@ -1632,7 +1597,6 @@ int app_switch_after_1_handler(struct ctl_table *table, int write,
 		/*
 		 * Switch finished
 		 */
-
 		spin_lock_irqsave(&switch_start_lock,flags);
 		switch_start = 0;
 		spin_unlock_irqrestore(&switch_start_lock,flags);
@@ -1640,20 +1604,27 @@ int app_switch_after_1_handler(struct ctl_table *table, int write,
 
 		/* for after page dump */
 
+
+
 		if(foreground_uid){
 			id = get_id_from_uid(foreground_uid);
-			trace_printk("foreground %d switch after start\n",foreground_uid);
-
-			if(past[id]->which_table)
-				atomic_set(&past[id]->after_index1,atomic_read(&past[id]->st_index1));
-			else
-				atomic_set(&past[id]->after_index0,atomic_read(&past[id]->st_index0));
-			
 			spin_lock_irqsave(&switch_start_lock,flags);
 			switch_after = 1;
 			spin_unlock_irqrestore(&switch_start_lock,flags);
-		
 
+			trace_printk("foreground %d switch after start\n",foreground_uid);
+
+		if(past[id]->which_table)
+			atomic_set(&past[id]->after_index1,atomic_read(&past[id]->st_index1));
+		else
+			atomic_set(&past[id]->after_index0,atomic_read(&past[id]->st_index0));
+
+		
+		spin_lock_irqsave(&switch_start_lock,flags);
+		switch_after = 1;
+		spin_unlock_irqrestore(&switch_start_lock,flags);
+		
+		
 		}
 
 
@@ -1671,6 +1642,7 @@ int app_switch_after_2_handler(struct ctl_table *table, int write,
 {
 
 
+
 	int rc = proc_dointvec_minmax(table,write,buffer,length,ppos);
 	unsigned long flags;
 	unsigned int id;
@@ -1850,7 +1822,7 @@ static int target_manager_should_run(void)
 	return stm_wait_cond  && !switch_start ; // should run in background
 }
 
-static int send_target_page(unsigned int id, pid_t tgid, unsigned long va, bool is_after){
+static int send_target_page(unsigned int id, pid_t tgid, unsigned long va){
 
        
 
@@ -1910,7 +1882,7 @@ static int send_target_page(unsigned int id, pid_t tgid, unsigned long va, bool
 							if(!cache_page)       // can't find the page from cache
 							{
 
-								if(_send_target_page(id, pte, pmd, va, mm, is_after)){
+								if(_send_target_page(id, pte, pmd, va, mm)){
 									
 									pte_unmap(pte);
 									return 1;
@@ -1960,8 +1932,6 @@ static int send_target_manager(void *arg)
 	int i;
 	int max_idx_l;
 	int max_idx_e;
-	int after_idx_l;
-	int after_idx_e;
 	int target_table;
 	pid_t tgid;
 	unsigned long va;
@@ -2008,16 +1978,12 @@ static int send_target_manager(void *arg)
 		swap_trace_table_e = past[id]->swap_trace_table0;
 		max_idx_l = atomic_read(&past[id]->st_index1);
 		swap_trace_table_l = past[id]->swap_trace_table1;
-		after_idx_e = atomic_read(&past[id]->after_index0);
-		after_idx_l = atomic_read(&past[id]->after_index1);
 	}
 	else{
 		max_idx_e = atomic_read(&past[id]->st_index1);
 		swap_trace_table_e = past[id]->swap_trace_table1;
 		max_idx_l = atomic_read(&past[id]->st_index0);
 		swap_trace_table_l = past[id]->swap_trace_table0;
-		after_idx_e = atomic_read(&past[id]->after_index1);
-		after_idx_l = atomic_read(&past[id]->after_index0);
 	}
 	/*
 			if(target_table){
@@ -2029,7 +1995,7 @@ static int send_target_manager(void *arg)
 				swap_trace_table_l = past[id]->swap_trace_table0;
 			}
 	*/
-			for( i = 0 ; i < after_idx_l +1 ; i++ ){
+			for( i = 0 ; i < max_idx_l ; i++ ){
 				if(switch_start){
 					target_flag = 0;
 					trace_printk(KERN_ERR "[REMOTE %s] switch started during sent\n", __func__);
@@ -2040,13 +2006,13 @@ static int send_target_manager(void *arg)
 					target_flag=1;
 					tgid = swap_trace_table_l[i].tgid;
 					va = swap_trace_table_l[i].va;
-					if(send_target_page(id/* ID */,tgid,va,i>=max_idx_l)){
+					if(send_target_page(id/* ID */,tgid,va)){
 						swap_trace_table_l[i].swapped=1;
 					}
 				}
 			}
 
-			for (i = max_idx_e ; i < after_idx_e+1; i++){
+			for (i = 0 ; i < max_idx_e ; i++){
 				if(switch_start){
 					target_flag = 0;
 					trace_printk(KERN_ERR "[REMOTE %s] switch started during sent\n", __func__);
@@ -2057,7 +2023,7 @@ static int send_target_manager(void *arg)
 					target_flag=1;
 					tgid = swap_trace_table_e[i].tgid;
 					va = swap_trace_table_e[i].va;
-					if(send_target_page(id/* ID */,tgid,va,true)){
+					if(send_target_page(id/* ID */,tgid,va)){
 						swap_trace_table_e[i].swapped=1;
 					}
 				}
@@ -2166,8 +2132,6 @@ void init_past(struct per_app_swap_trace *past){
 	int i;
 	atomic_set(&past->st_index0,-1);
 	atomic_set(&past->st_index1,-1);
-	atomic_set(&past->after_index0,-1);
-	atomic_set(&past->after_index1,-1);
 	past->st_should_check = 0;
 	past->which_table = 0;
 	for(i=0;i<NUM_STT_ENTRIES;i++){
@@ -2192,12 +2156,13 @@ static int __init remote_swap_init(void)
 			
 	target_percentage = 50;
 
-	//per_app structs init
+
 	for(i=0;i<19;i++){
 		struct perapp_cluster *cluster;
 		cluster=&pac[i];
 		cluster_set_null_1(&cluster->index);
 	}
+	//per_app structs init
 	for(i=0;i<9;i++){
 		past[i]=(struct per_app_swap_trace *)vmalloc(sizeof(struct per_app_swap_trace));
 		init_past(past[i]);
@@ -2206,11 +2171,11 @@ static int __init remote_swap_init(void)
 	preempted_cold_task = NULL;
 
 	error = send_target_managers_init();
-	if(unlikely(error))
+	if (unlikely(error))
 		return error;
 
 	error = sys_cold_counter_init();
-	if(unlikely(error))
+	if (unlikely(error))
 		return error;
 
 	return 0;

diff --git a/msm-google/jyp/remote_OR.c b/msm-google/jyp/remote_OR.c
index de3bcd4d6..2d25ecff7 100644
--- a/msm-google/jyp/remote_OR.c
+++ b/msm-google/jyp/remote_OR.c
@@ -78,7 +78,7 @@ int target_percentage;
 
 struct task_struct *preempted_cold_task;
 
-struct perapp_cluster pac[10];
+struct perapp_cluster pac[19];
 
 struct task_struct *send_target_manager_thread;
 struct task_struct *send_target_alarm_thread;
@@ -2157,13 +2157,13 @@ static int __init remote_swap_init(void)
 	target_percentage = 50;
 
 
-
-	//per_app structs init
-	for(i=0;i<9;i++){
+	for(i=0;i<19;i++){
 		struct perapp_cluster *cluster;
 		cluster=&pac[i];
 		cluster_set_null_1(&cluster->index);
-
+	}
+	//per_app structs init
+	for(i=0;i<9;i++){
 		past[i]=(struct per_app_swap_trace *)vmalloc(sizeof(struct per_app_swap_trace));
 		init_past(past[i]);
 	}
@@ -2184,10 +2184,12 @@ static int __init remote_swap_init(void)
 static void __exit remote_swap_exit(void){
 
 	int i;
-	for(i=0;i<9;i++){
+	for(i=0;i<19;i++){
 		struct perapp_cluster *cluster;
 		cluster=&pac[i];
 		cluster_set_null_1(&cluster->index);
+	}
+	for(i=0;i<9;i++){
 		vfree(past[i]);
 	}
 	kthread_stop(send_target_manager_thread);
diff --git a/msm-google/mm/memory.c b/msm-google/mm/memory.c
index 4fe3a7b27..edb98e090 100644
--- a/msm-google/mm/memory.c
+++ b/msm-google/mm/memory.c
@@ -3141,7 +3141,6 @@ int do_swap_page(struct vm_fault *vmf)
 #ifdef CONFIG_APP_AWARE
 
 	if(switch_start && foreground_uid && !excepted){
-	printk(KERN_ERR "1!!\n");
 		if(past[id]->which_table){
 			st_idx_ptr = &past[id]->st_index1;
 			swap_trace_table = past[id]->swap_trace_table1;
@@ -3151,11 +3150,8 @@ int do_swap_page(struct vm_fault *vmf)
 			swap_trace_table = past[id]->swap_trace_table0;
 		}
 
-	printk(KERN_ERR "2!!\n");
 		idx = atomic_inc_return(st_idx_ptr);
-	printk(KERN_ERR "3!!\n");
 		if(idx<NUM_STT_ENTRIES-1){
-	printk(KERN_ERR "4!!\n");
 		swap_trace_table[idx].tgid = current->tgid;
 		swap_trace_table[idx].va = vmf->address;
 		swap_trace_table[idx].to_nbd = 0;
@@ -3164,14 +3160,11 @@ int do_swap_page(struct vm_fault *vmf)
 		}
 		else
 			atomic_set(st_idx_ptr,NUM_STT_ENTRIES-1);
-	printk(KERN_ERR "5!!\n");
 	}
 	
 	if(switch_after && foreground_uid){
-	printk(KERN_ERR "6!!\n");
 		
 		id = get_id_from_uid(foreground_uid);
-	printk(KERN_ERR "7!!\n");
 		
 		if(past[id]->which_table){
 			st_idx_ptr = &past[id]->after_index1;
@@ -3181,10 +3174,8 @@ int do_swap_page(struct vm_fault *vmf)
 			st_idx_ptr = &past[id]->after_index0;
 			swap_trace_table = past[id]->swap_trace_table0;
 		}
-	printk(KERN_ERR "8!!\n");
-		if(idx<NUM_STT_ENTRIES-1){
-	printk(KERN_ERR "9!!\n");
 		idx = atomic_inc_return(st_idx_ptr);
+		if(idx<NUM_STT_ENTRIES-1){
 		swap_trace_table[idx].tgid = current->tgid;
 		swap_trace_table[idx].va = vmf->address;
 		swap_trace_table[idx].to_nbd = 0;
@@ -3194,7 +3185,6 @@ int do_swap_page(struct vm_fault *vmf)
 		else
 			atomic_set(st_idx_ptr,NUM_STT_ENTRIES-1);
 	
-		printk(KERN_ERR "10!!\n");
 	}
 
 
