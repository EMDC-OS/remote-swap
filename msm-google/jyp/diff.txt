diff --git a/msm-google/jyp/remote.c b/msm-google/jyp/remote.c
index 080ec6111..e10c94f1c 100644
--- a/msm-google/jyp/remote.c
+++ b/msm-google/jyp/remote.c
@@ -78,7 +78,7 @@ int target_percentage;
 
 struct task_struct *preempted_cold_task;
 
-struct perapp_cluster pac[10];
+struct perapp_cluster pac[19];
 
 struct task_struct *send_target_manager_thread;
 struct task_struct *send_target_alarm_thread;
@@ -165,7 +165,7 @@ void wake_up_send_target_manager(void)
 
 
 
-static int _send_target_page(unsigned int id, pte_t *pte, pmd_t *pmd, unsigned long vpage, struct mm_struct *mm){
+static int _send_target_page(unsigned int id, pte_t *pte, pmd_t *pmd, unsigned long vpage, struct mm_struct *mm, bool is_after){
 
 
 
@@ -194,7 +194,7 @@ static int _send_target_page(unsigned int id, pte_t *pte, pmd_t *pmd, unsigned l
 					
 	//trace_printk(KERN_ERR "[REMOTE %s] alloc page %llx\n", __func__,page_to_pfn(page));
 
-		new_entry = get_swap_page_of_id(id);
+		new_entry = get_swap_page_of_id(id+10*is_after);
 	new_pte = swp_entry_and_counter_to_pte(new_entry,id);
 	//if Prefetch target, type==1 && counter(id)==id
 	lock_page(page);
@@ -238,7 +238,7 @@ static int _send_target_page(unsigned int id, pte_t *pte, pmd_t *pmd, unsigned l
 	}
 	
 	set_pte(orig_pte, new_pte);
-	trace_printk("target sent id %d: %d %llx %llx\n",id, mm->owner->tgid, vpage, swp_offset(new_entry));
+	trace_printk("target sent id %d: cluster %d, %d %llx %llx\n",id,id+10*is_after,mm->owner->tgid, vpage, swp_offset(new_entry));
 	swap_free(entry);
 	ret=1;
 unlock:
@@ -838,11 +838,14 @@ static void prefetch_work(struct work_struct *work)
 	struct prefetch_work *tew;
 	int max_idx_l;
 	int max_idx_e;
+	int after_idx_e;
+	int after_idx_l;
 	struct swap_trace_entry *swap_trace_table_l;
 	struct swap_trace_entry *swap_trace_table_e;
 	pid_t tgid;
 	unsigned long va;
 	struct blk_plug plug;
+	struct blk_plug plug_after;
 	int i;
 	unsigned int id;
 	int target_table;
@@ -856,15 +859,18 @@ static void prefetch_work(struct work_struct *work)
 		swap_trace_table_e = past[id]->swap_trace_table0;
 		max_idx_l = atomic_read(&past[id]->st_index1);
 		swap_trace_table_l = past[id]->swap_trace_table1;
+		after_idx_e = atomic_read(&past[id]->after_index0);
+		after_idx_l = atomic_read(&past[id]->after_index1);
 	}
 	else{
 		max_idx_e = atomic_read(&past[id]->st_index1);
 		swap_trace_table_e = past[id]->swap_trace_table1;
 		max_idx_l = atomic_read(&past[id]->st_index0);
 		swap_trace_table_l = past[id]->swap_trace_table0;
+		after_idx_e = atomic_read(&past[id]->after_index1);
+		after_idx_l = atomic_read(&past[id]->after_index0);
 	}
 
-
 	blk_start_plug(&plug);
 	for( i = 0 ; i < max_idx_l ; i++ ){
 		//trace_printk("prefetch table %d: %d %llx, %d %d\n",target_table,swap_trace_table_l[i].tgid,swap_trace_table_l[i].va,swap_trace_table_l[i].to_nbd,swap_trace_table_l[i].swapped);
@@ -872,20 +878,30 @@ static void prefetch_work(struct work_struct *work)
 			tgid = swap_trace_table_l[i].tgid;
 			va = swap_trace_table_l[i].va;
 			prefetch_target_page(tgid,va);
-			swap_trace_table_l[i].swapped = 0;
+		}
+	}
+	blk_finish_plug(&plug);
+
+
+	blk_start_plug(&plug_after);
+	for( i = max_idx_l ; i < after_idx_l ; i++ ){
+		//trace_printk("prefetch table %d: %d %llx, %d %d\n",target_table,swap_trace_table_l[i].tgid,swap_trace_table_l[i].va,swap_trace_table_l[i].to_nbd,swap_trace_table_l[i].swapped);
+		if(swap_trace_table_l[i].to_nbd && swap_trace_table_l[i].swapped){
+			tgid = swap_trace_table_l[i].tgid;
+			va = swap_trace_table_l[i].va;
+			prefetch_target_page(tgid,va);
 		}
 	}
 
 
-	for( i = 0 ; i < max_idx_e ; i++ ){
+	for( i = max_idx_e ; i < after_idx_e ; i++ ){
 		if(swap_trace_table_e[i].to_nbd && swap_trace_table_e[i].swapped){
 			tgid = swap_trace_table_e[i].tgid;
 			va = swap_trace_table_e[i].va;
 			prefetch_target_page(tgid,va);
-			swap_trace_table_e[i].swapped = 0;
 		}
 	}
-	blk_finish_plug(&plug);
+	blk_finish_plug(&plug_after);
 	lru_add_drain();
 
 	kfree(tew);
@@ -897,6 +913,8 @@ static void miss_page_work(struct work_struct *work)
 	struct miss_page_work *tew;
 	int max_idx_l;
 	int max_idx_e;
+	int after_idx_l;
+	int after_idx_e;
 	struct swap_trace_entry *swap_trace_table_l;
 	struct swap_trace_entry *swap_trace_table_e;
 	pid_t tgid;
@@ -913,17 +931,21 @@ static void miss_page_work(struct work_struct *work)
 		swap_trace_table_e = past[id]->swap_trace_table0;
 		max_idx_l = atomic_read(&past[id]->st_index1);
 		swap_trace_table_l = past[id]->swap_trace_table1;
+		after_idx_e = atomic_read(&past[id]->after_index0);
+		after_idx_l = atomic_read(&past[id]->after_index1);
 	}
 	else{
 		max_idx_e = atomic_read(&past[id]->st_index1);
 		swap_trace_table_e = past[id]->swap_trace_table1;
 		max_idx_l = atomic_read(&past[id]->st_index0);
 		swap_trace_table_l = past[id]->swap_trace_table0;
+		after_idx_e = atomic_read(&past[id]->after_index1);
+		after_idx_l = atomic_read(&past[id]->after_index0);
 	}
 
 //	blk_start_plug(&plug);
-	for( i = 0 ; i < max_idx_l ; i++ ){
-		if(swap_trace_table_l[i].to_nbd) // && swapped
+	for( i = 0 ; i < after_idx_l ; i++ ){
+		if(swap_trace_table_l[i].to_nbd && swap_trace_table_l[i].swapped ) // && swapped
 		{
 			tgid = swap_trace_table_l[i].tgid;
 			va = swap_trace_table_l[i].va;
@@ -931,9 +953,8 @@ static void miss_page_work(struct work_struct *work)
 		}
 	}
 
-
-	for( i = 0 ; i < max_idx_e ; i++ ){
-		if(swap_trace_table_e[i].to_nbd) // && swapped
+	for( i = 0 ; i < after_idx_e ; i++ ){
+		if(swap_trace_table_e[i].to_nbd && swap_trace_table_e[i].swapped) // && swapped
 		{
 			tgid = swap_trace_table_e[i].tgid;
 			va = swap_trace_table_e[i].va;
@@ -1419,6 +1440,8 @@ int update_to_nbd_flag(unsigned int id, int percentage){
 	int idx_l; //latter
 	int max_idx_e;
 	int max_idx_l;
+	int after_idx_e;
+	int after_idx_l;
 	int cnt=0;
 	struct swap_trace_entry *swap_trace_table_e;
 	struct swap_trace_entry *swap_trace_table_l;
@@ -1433,12 +1456,16 @@ int update_to_nbd_flag(unsigned int id, int percentage){
 		swap_trace_table_e = past[id]->swap_trace_table0;
 		max_idx_l = atomic_read(&past[id]->st_index1);
 		swap_trace_table_l = past[id]->swap_trace_table1;
+		after_idx_e = atomic_read(&past[id]->after_index0);
+		after_idx_l = atomic_read(&past[id]->after_index1);
 	}
 	else{
 		max_idx_e = atomic_read(&past[id]->st_index1);
 		swap_trace_table_e = past[id]->swap_trace_table1;
 		max_idx_l = atomic_read(&past[id]->st_index0);
 		swap_trace_table_l = past[id]->swap_trace_table0;
+		after_idx_e = atomic_read(&past[id]->after_index1);	
+		after_idx_l = atomic_read(&past[id]->after_index0);
 	}
 
 	idx_e = max_idx_e * percentage/100;
@@ -1448,7 +1475,7 @@ int update_to_nbd_flag(unsigned int id, int percentage){
 
 	/* AND version!*/
 	
-/*
+
 	while(idx_l <= max_idx_l){
 		idx_e = max_idx_e * percentage/100;
 		while(idx_e <= max_idx_e){
@@ -1462,23 +1489,25 @@ int update_to_nbd_flag(unsigned int id, int percentage){
 		}
 		idx_l++;
 	}
-*/
 
-	/* OR version! */
-	while(idx_e <= max_idx_e){
+	idx_e = max_idx_e;
+	idx_l = max_idx_l;
+	
+
+	while(idx_e <= after_idx_e){
 		swap_trace_table_e[idx_e].to_nbd = 1;
 		idx_e++;
 		cnt++;
 	}
-	while(idx_l <= max_idx_l){
+	while(idx_l <= after_idx_l){
 		swap_trace_table_l[idx_l].to_nbd = 1;
 		idx_l++;
 		cnt++;
 	}
-	idx_e = max_idx_e * percentage/100;
-	while(idx_e <= max_idx_e){
-		idx_l = max_idx_l * percentage/100;
-		while(idx_l <= max_idx_l){
+	idx_e = max_idx_e;
+	while(idx_e <= after_idx_e){
+		idx_l = max_idx_l;
+		while(idx_l <= after_idx_l){
 			if( swap_trace_table_e[idx_e].va == swap_trace_table_l[idx_l].va &&
 				swap_trace_table_e[idx_e].tgid == swap_trace_table_l[idx_l].tgid){
 				swap_trace_table_e[idx_e].to_nbd = 0;
@@ -1493,11 +1522,8 @@ int update_to_nbd_flag(unsigned int id, int percentage){
 
 	
 	// for dump
-	
-
-	idx_l = max_idx_l * percentage/100;
 
-	trace_printk("appid %d: table %d is latter, total target %d max idx e, l -> %d %d\n",id, past[id]->which_table,cnt,max_idx_e,max_idx_l);
+	trace_printk("appid %d: table %d is latter, total target %d max idx e, l -> %d %d, after %d %d\n",id, past[id]->which_table,cnt,max_idx_e,max_idx_l,after_idx_e - max_idx_e, after_idx_l - max_idx_l);
 /*
 	while(idx_l <= max_idx_l){
 		if( swap_trace_table_l[idx_l].to_nbd )
@@ -1594,10 +1620,10 @@ int app_switch_after_1_handler(struct ctl_table *table, int write,
 		return rc;
 	if(write){
 	
-		struct task_struct *p;
 		/*
 		 * Switch finished
 		 */
+
 		spin_lock_irqsave(&switch_start_lock,flags);
 		switch_start = 0;
 		spin_unlock_irqrestore(&switch_start_lock,flags);
@@ -1605,15 +1631,25 @@ int app_switch_after_1_handler(struct ctl_table *table, int write,
 
 		/* for after page dump */
 
-
-
 		if(foreground_uid){
 			id = get_id_from_uid(foreground_uid);
 			spin_lock_irqsave(&switch_start_lock,flags);
 			switch_after = 1;
 			spin_unlock_irqrestore(&switch_start_lock,flags);
 
-			trace_printk("foreground %d switch after start",foreground_uid);
+			trace_printk("foreground %d switch after start\n",foreground_uid);
+
+		if(past[id]->which_table)
+			atomic_set(&past[id]->after_index1,atomic_read(&past[id]->st_index1));
+		else
+			atomic_set(&past[id]->after_index0,atomic_read(&past[id]->st_index0));
+
+		
+		spin_lock_irqsave(&switch_start_lock,flags);
+		switch_after = 1;
+		spin_unlock_irqrestore(&switch_start_lock,flags);
+		
+		
 		}
 
 
@@ -1643,6 +1679,8 @@ int app_switch_after_2_handler(struct ctl_table *table, int write,
 		/*
 		 * Switch finished
 		 */
+			
+		trace_printk("foreground %d switch after end\n",foreground_uid);
 		spin_lock_irqsave(&switch_start_lock,flags);
 		switch_after = 0;
 		spin_unlock_irqrestore(&switch_start_lock,flags);
@@ -1809,7 +1847,7 @@ static int target_manager_should_run(void)
 	return stm_wait_cond  && !switch_start ; // should run in background
 }
 
-static int send_target_page(unsigned int id, pid_t tgid, unsigned long va){
+static int send_target_page(unsigned int id, pid_t tgid, unsigned long va, bool is_after){
 
        
 
@@ -1869,7 +1907,7 @@ static int send_target_page(unsigned int id, pid_t tgid, unsigned long va){
 							if(!cache_page)       // can't find the page from cache
 							{
 
-								if(_send_target_page(id, pte, pmd, va, mm)){
+								if(_send_target_page(id, pte, pmd, va, mm, is_after)){
 									
 									pte_unmap(pte);
 									return 1;
@@ -1919,6 +1957,8 @@ static int send_target_manager(void *arg)
 	int i;
 	int max_idx_l;
 	int max_idx_e;
+	int after_idx_l;
+	int after_idx_e;
 	int target_table;
 	pid_t tgid;
 	unsigned long va;
@@ -1965,12 +2005,16 @@ static int send_target_manager(void *arg)
 		swap_trace_table_e = past[id]->swap_trace_table0;
 		max_idx_l = atomic_read(&past[id]->st_index1);
 		swap_trace_table_l = past[id]->swap_trace_table1;
+		after_idx_e = atomic_read(&past[id]->after_index0);
+		after_idx_l = atomic_read(&past[id]->after_index1);
 	}
 	else{
 		max_idx_e = atomic_read(&past[id]->st_index1);
 		swap_trace_table_e = past[id]->swap_trace_table1;
 		max_idx_l = atomic_read(&past[id]->st_index0);
 		swap_trace_table_l = past[id]->swap_trace_table0;
+		after_idx_e = atomic_read(&past[id]->after_index1);
+		after_idx_l = atomic_read(&past[id]->after_index0);
 	}
 	/*
 			if(target_table){
@@ -1982,7 +2026,7 @@ static int send_target_manager(void *arg)
 				swap_trace_table_l = past[id]->swap_trace_table0;
 			}
 	*/
-			for( i = 0 ; i < max_idx_l ; i++ ){
+			for( i = 0 ; i < after_idx_l ; i++ ){
 				if(switch_start){
 					target_flag = 0;
 					trace_printk(KERN_ERR "[REMOTE %s] switch started during sent\n", __func__);
@@ -1993,13 +2037,13 @@ static int send_target_manager(void *arg)
 					target_flag=1;
 					tgid = swap_trace_table_l[i].tgid;
 					va = swap_trace_table_l[i].va;
-					if(send_target_page(id/* ID */,tgid,va)){
+					if(send_target_page(id/* ID */,tgid,va,i>=max_idx_l)){
 						swap_trace_table_l[i].swapped=1;
 					}
 				}
 			}
 
-			for (i = 0 ; i < max_idx_e ; i++){
+			for (i = max_idx_e ; i < after_idx_e ; i++){
 				if(switch_start){
 					target_flag = 0;
 					trace_printk(KERN_ERR "[REMOTE %s] switch started during sent\n", __func__);
@@ -2010,7 +2054,7 @@ static int send_target_manager(void *arg)
 					target_flag=1;
 					tgid = swap_trace_table_e[i].tgid;
 					va = swap_trace_table_e[i].va;
-					if(send_target_page(id/* ID */,tgid,va)){
+					if(send_target_page(id/* ID */,tgid,va,true)){
 						swap_trace_table_e[i].swapped=1;
 					}
 				}
@@ -2143,14 +2187,13 @@ static int __init remote_swap_init(void)
 			
 	target_percentage = 50;
 
-
-
 	//per_app structs init
-	for(i=0;i<9;i++){
+	for(i=0;i<19;i++){
 		struct perapp_cluster *cluster;
 		cluster=&pac[i];
 		cluster_set_null_1(&cluster->index);
-
+	}
+	for(i=0;i<9;i++){
 		past[i]=(struct per_app_swap_trace *)vmalloc(sizeof(struct per_app_swap_trace));
 		init_past(past[i]);
 	}
@@ -2158,11 +2201,11 @@ static int __init remote_swap_init(void)
 	preempted_cold_task = NULL;
 
 	error = send_target_managers_init();
-	if (unlikely(error))
+	if(unlikely(error))
 		return error;
 
 	error = sys_cold_counter_init();
-	if (unlikely(error))
+	if(unlikely(error))
 		return error;
 
 	return 0;
@@ -2171,10 +2214,12 @@ static int __init remote_swap_init(void)
 static void __exit remote_swap_exit(void){
 
 	int i;
-	for(i=0;i<9;i++){
+	for(i=0;i<19;i++){
 		struct perapp_cluster *cluster;
 		cluster=&pac[i];
 		cluster_set_null_1(&cluster->index);
+	}
+	for(i=0;i<9;i++){
 		vfree(past[i]);
 	}
 	kthread_stop(send_target_manager_thread);
